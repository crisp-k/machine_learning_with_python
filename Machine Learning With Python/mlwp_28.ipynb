{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing with Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['To be, or not to be, that is the question:', \"Whether 'tis nobler in the mind to suffer\", 'The slings and arrows of outrageous fortune']\n"
     ]
    }
   ],
   "source": [
    "corpus = ['To be, or not to be, that is the question:',\n",
    "          'Whether \\'tis nobler in the mind to suffer',\n",
    "          'The slings and arrows of outrageous fortune']\n",
    "\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer()\n"
     ]
    }
   ],
   "source": [
    "vectorizor = text.CountVectorizer()\n",
    "print(vectorizor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizor.fit(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary:  {'to': 18, 'be': 2, 'or': 10, 'not': 8, 'that': 15, 'is': 5, 'the': 16, 'question': 12, 'whether': 19, 'tis': 17, 'nobler': 7, 'in': 4, 'mind': 6, 'suffer': 14, 'slings': 13, 'and': 0, 'arrows': 1, 'of': 9, 'outrageous': 11, 'fortune': 3}\n"
     ]
    }
   ],
   "source": [
    "print('Vocabulary: ', vectorizor.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and' 'arrows' 'be' 'fortune' 'in' 'is' 'mind' 'nobler' 'not' 'of' 'or'\n",
      " 'outrageous' 'question' 'slings' 'suffer' 'that' 'the' 'tis' 'to'\n",
      " 'whether']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizor.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['to', 'be', 'or', 'not', 'that', 'is', 'the', 'question', 'whether', 'tis', 'nobler', 'in', 'mind', 'suffer', 'slings', 'and', 'arrows', 'of', 'outrageous', 'fortune']\n"
     ]
    }
   ],
   "source": [
    "print(list(vectorizor.vocabulary_.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2)\t2\n",
      "  (0, 5)\t1\n",
      "  (0, 8)\t1\n",
      "  (0, 10)\t1\n",
      "  (0, 12)\t1\n",
      "  (0, 15)\t1\n",
      "  (0, 16)\t1\n",
      "  (0, 18)\t2\n",
      "  (1, 4)\t1\n",
      "  (1, 6)\t1\n",
      "  (1, 7)\t1\n",
      "  (1, 14)\t1\n",
      "  (1, 16)\t1\n",
      "  (1, 17)\t1\n",
      "  (1, 18)\t1\n",
      "  (1, 19)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 3)\t1\n",
      "  (2, 9)\t1\n",
      "  (2, 11)\t1\n",
      "  (2, 13)\t1\n",
      "  (2, 16)\t1\n"
     ]
    }
   ],
   "source": [
    "token_count_matrix = vectorizor.transform(corpus)\n",
    "print(token_count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 2, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 2, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1],\n",
       "       [1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_tcm = token_count_matrix.toarray()\n",
    "dense_tcm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to\n",
      "be\n",
      "or\n",
      "not\n",
      "that\n",
      "is\n",
      "the\n",
      "question\n",
      "whether\n",
      "tis\n",
      "nobler\n",
      "in\n",
      "mind\n",
      "suffer\n",
      "slings\n",
      "and\n",
      "arrows\n",
      "of\n",
      "outrageous\n",
      "fortune\n"
     ]
    }
   ],
   "source": [
    "feature_names = vectorizor.get_feature_names_out()\n",
    "\n",
    "for el in vectorizor.vocabulary_:\n",
    "    print(el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>arrows</th>\n",
       "      <th>be</th>\n",
       "      <th>fortune</th>\n",
       "      <th>in</th>\n",
       "      <th>is</th>\n",
       "      <th>mind</th>\n",
       "      <th>nobler</th>\n",
       "      <th>not</th>\n",
       "      <th>of</th>\n",
       "      <th>or</th>\n",
       "      <th>outrageous</th>\n",
       "      <th>question</th>\n",
       "      <th>slings</th>\n",
       "      <th>suffer</th>\n",
       "      <th>that</th>\n",
       "      <th>the</th>\n",
       "      <th>tis</th>\n",
       "      <th>to</th>\n",
       "      <th>whether</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>corpus_0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>corpus_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>corpus_2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          and  arrows  be  fortune  in  is  mind  nobler  not  of  or  \\\n",
       "corpus_0    0       0   2        0   0   1     0       0    1   0   1   \n",
       "corpus_1    0       0   0        0   1   0     1       1    0   0   0   \n",
       "corpus_2    1       1   0        1   0   0     0       0    0   1   0   \n",
       "\n",
       "          outrageous  question  slings  suffer  that  the  tis  to  whether  \n",
       "corpus_0           0         1       0       0     1    1    0   2        0  \n",
       "corpus_1           0         0       0       1     0    1    1   1        1  \n",
       "corpus_2           1         0       1       0     0    1    0   0        0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(data=dense_tcm, index=['corpus_0', 'corpus_1', 'corpus_2'],\n",
    "             columns=vectorizor.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of times \"be\" occurs in:\n",
      "    \"To be, or not to be, that is the question:\": 2\n",
      "    \"Whether 'tis nobler in the mind to suffer\": 0\n",
      "    \"The slings and arrows of outrageous fortune\": 0\n"
     ]
    }
   ],
   "source": [
    "word = 'be'\n",
    "\n",
    "i = 1\n",
    "j = vectorizor.vocabulary_[word]\n",
    "\n",
    "print('number of times \"' + word+ '\" occurs in:')\n",
    "\n",
    "for i in range(len(corpus)):\n",
    "    print('    \"' + corpus[i] + '\": ' + str(dense_tcm[i][j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 1, 2, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 2, 0, 0, 0]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = 'That is the question and it is nobler in the mind.'\n",
    "\n",
    "vectorizor.transform([txt]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and' 'arrows' 'be' 'fortune' 'in' 'is' 'mind' 'nobler' 'not' 'of' 'or'\n",
      " 'outrageous' 'question' 'slings' 'suffer' 'that' 'the' 'tis' 'to'\n",
      " 'whether']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizor.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'to': 18, 'be': 2, 'or': 10, 'not': 8, 'that': 15, 'is': 5, 'the': 16, 'question': 12, 'whether': 19, 'tis': 17, 'nobler': 7, 'in': 4, 'mind': 6, 'suffer': 14, 'slings': 13, 'and': 0, 'arrows': 1, 'of': 9, 'outrageous': 11, 'fortune': 3}\n"
     ]
    }
   ],
   "source": [
    "print(vectorizor.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import text\n",
    "\n",
    "corpus = ['It does not matter what you are doing, just do it!',\n",
    "          'Would you work if you won the lottery?',\n",
    "          'You like Python, he likes Python, we like Python, everybody loves Python!',\n",
    "          'You said: \"I wish I were a Python programmer\"',\n",
    "          'You can stay here, if you want to. I would, if I were you.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 9)\t2\n",
      "  (0, 10)\t1\n",
      "  (0, 15)\t1\n",
      "  (0, 16)\t1\n",
      "  (0, 26)\t1\n",
      "  (0, 31)\t1\n",
      "  (1, 8)\t1\n",
      "  (1, 13)\t1\n",
      "  (1, 21)\t1\n",
      "  (1, 28)\t1\n",
      "  (1, 29)\t1\n",
      "  (1, 30)\t1\n",
      "  (1, 31)\t2\n",
      "  (2, 5)\t1\n",
      "  (2, 6)\t1\n",
      "  (2, 11)\t2\n",
      "  (2, 12)\t1\n",
      "  (2, 14)\t1\n",
      "  (2, 18)\t4\n",
      "  (2, 24)\t1\n",
      "  (2, 31)\t1\n",
      "  (3, 17)\t1\n",
      "  (3, 18)\t1\n",
      "  (3, 19)\t1\n",
      "  (3, 25)\t1\n",
      "  (3, 27)\t1\n",
      "  (3, 31)\t1\n",
      "  (4, 1)\t1\n",
      "  (4, 7)\t1\n",
      "  (4, 8)\t2\n",
      "  (4, 20)\t1\n",
      "  (4, 22)\t1\n",
      "  (4, 23)\t1\n",
      "  (4, 25)\t1\n",
      "  (4, 30)\t1\n",
      "  (4, 31)\t3\n"
     ]
    }
   ],
   "source": [
    "vectorizor = text.CountVectorizer()\n",
    "vectorizor.fit(corpus)\n",
    "\n",
    "token_count_matrix = vectorizor.transform(corpus)\n",
    "print(token_count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.09861229, 2.09861229, 2.09861229, 2.09861229, 2.09861229,\n",
       "       2.09861229, 2.09861229, 2.09861229, 1.69314718, 2.09861229,\n",
       "       2.09861229, 2.09861229, 2.09861229, 2.09861229, 2.09861229,\n",
       "       2.09861229, 2.09861229, 2.09861229, 1.69314718, 2.09861229,\n",
       "       2.09861229, 2.09861229, 2.09861229, 2.09861229, 2.09861229,\n",
       "       1.69314718, 2.09861229, 2.09861229, 2.09861229, 2.09861229,\n",
       "       1.69314718, 1.        ])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf = text.TfidfTransformer()\n",
    "\n",
    "tf_idf.fit(token_count_matrix)\n",
    "\n",
    "tf_idf.idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6931471805599454"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf.idf_[vectorizor.vocabulary_['python']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da = vectorizor.transform(corpus).toarray()\n",
    "i = 0\n",
    "\n",
    "word_ind = vectorizor.vocabulary_['would']\n",
    "da[i][word_ind]\n",
    "da[:, word_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you            : 1.000\n",
      "if             : 1.693\n",
      "python         : 1.693\n",
      "were           : 1.693\n",
      "would          : 1.693\n",
      "are            : 2.099\n",
      "can            : 2.099\n",
      "do             : 2.099\n",
      "does           : 2.099\n",
      "doing          : 2.099\n",
      "everybody      : 2.099\n",
      "he             : 2.099\n",
      "here           : 2.099\n",
      "it             : 2.099\n",
      "just           : 2.099\n",
      "like           : 2.099\n",
      "likes          : 2.099\n",
      "lottery        : 2.099\n",
      "loves          : 2.099\n",
      "matter         : 2.099\n",
      "not            : 2.099\n",
      "programmer     : 2.099\n",
      "said           : 2.099\n",
      "stay           : 2.099\n",
      "the            : 2.099\n",
      "to             : 2.099\n",
      "want           : 2.099\n",
      "we             : 2.099\n",
      "what           : 2.099\n",
      "wish           : 2.099\n",
      "won            : 2.099\n",
      "work           : 2.099\n"
     ]
    }
   ],
   "source": [
    "word_weight_list = list(zip(vectorizor.get_feature_names_out(), tf_idf.idf_))\n",
    "\n",
    "word_weight_list.sort(key=lambda x:x[1])\n",
    "\n",
    "for word, idf_weight in word_weight_list:\n",
    "    print(f'{word:15s}: {idf_weight:4.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['It does not matter what you are doing, just do it!', 'Would you work if you won the lottery?', 'You like Python, he likes Python, we like Python, everybody loves Python!', 'You said: \"I wish I were a Python programmer\"', 'You can stay here, if you want to. I would, if I were you.']\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import log\n",
    "from sklearn.feature_extraction import text\n",
    "\n",
    "n = len(corpus)\n",
    "\n",
    "vectorizor = text.CountVectorizer()\n",
    "vectorizor.fit(corpus)\n",
    "da = vectorizor.transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf(t, d, mode='raw'):\n",
    "    if t in vectorizor.vocabulary_:\n",
    "        word_ind = vectorizor.vocabulary_[t]\n",
    "        t_occurences = da[d, word_ind]\n",
    "    else:\n",
    "        t_occurences = 0\n",
    "\n",
    "    if mode == 'raw':\n",
    "        result = t_occurences\n",
    "    elif mode == 'length':\n",
    "        all_terms = (da[d] > 0).sum() \n",
    "        result = t_occurences / all_terms\n",
    "    elif mode == 'log':\n",
    "        result = log(1 + t_occurences)\n",
    "    elif mode == 'augfreq':\n",
    "        result = 0.5 + 0.5 * t_occurences / da[d].max()\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   raw    length  log    augmented freq\n",
      "\n",
      "'matter' in 'It does not matter what you are doing, just do it!'\n",
      "   1.00   0.10   0.69   0.75\n",
      "'matter' in 'Would you work if you won the lottery?'\n",
      "   0.00   0.00   0.00   0.50\n",
      "'matter' in 'You like Python, he likes Python, we like Python, everybody loves Python!'\n",
      "   0.00   0.00   0.00   0.50\n",
      "'matter' in 'You said: \"I wish I were a Python programmer\"'\n",
      "   0.00   0.00   0.00   0.50\n",
      "'matter' in 'You can stay here, if you want to. I would, if I were you.'\n",
      "   0.00   0.00   0.00   0.50\n",
      "'python' in 'It does not matter what you are doing, just do it!'\n",
      "   0.00   0.00   0.00   0.50\n",
      "'python' in 'Would you work if you won the lottery?'\n",
      "   0.00   0.00   0.00   0.50\n",
      "'python' in 'You like Python, he likes Python, we like Python, everybody loves Python!'\n",
      "   4.00   0.50   1.61   1.00\n",
      "'python' in 'You said: \"I wish I were a Python programmer\"'\n",
      "   1.00   0.17   0.69   1.00\n",
      "'python' in 'You can stay here, if you want to. I would, if I were you.'\n",
      "   0.00   0.00   0.00   0.50\n",
      "'would' in 'It does not matter what you are doing, just do it!'\n",
      "   0.00   0.00   0.00   0.50\n",
      "'would' in 'Would you work if you won the lottery?'\n",
      "   1.00   0.14   0.69   0.75\n",
      "'would' in 'You like Python, he likes Python, we like Python, everybody loves Python!'\n",
      "   0.00   0.00   0.00   0.50\n",
      "'would' in 'You said: \"I wish I were a Python programmer\"'\n",
      "   0.00   0.00   0.00   0.50\n",
      "'would' in 'You can stay here, if you want to. I would, if I were you.'\n",
      "   1.00   0.11   0.69   0.67"
     ]
    }
   ],
   "source": [
    "print('   raw    length  log    augmented freq')\n",
    "\n",
    "for term in ['matter', 'python', 'would']:\n",
    "    for docu_index in range(len(corpus)):\n",
    "        d = corpus[docu_index]\n",
    "\n",
    "        print(f\"\\n'{term}' in '{d}'\")\n",
    "\n",
    "        for mode in ['raw', 'length', 'log', 'augfreq']:\n",
    "            x = tf(term, docu_index, mode=mode)\n",
    "            print(f\"{x:7.2f}\", end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['you', 1.0]\n",
      "['if', 1.6931471805599454]\n",
      "['python', 1.6931471805599454]\n",
      "['were', 1.6931471805599454]\n",
      "['would', 1.6931471805599454]\n",
      "['are', 2.09861228866811]\n",
      "['can', 2.09861228866811]\n",
      "['do', 2.09861228866811]\n",
      "['does', 2.09861228866811]\n",
      "['doing', 2.09861228866811]\n",
      "['everybody', 2.09861228866811]\n",
      "['he', 2.09861228866811]\n",
      "['here', 2.09861228866811]\n",
      "['it', 2.09861228866811]\n",
      "['just', 2.09861228866811]\n",
      "['like', 2.09861228866811]\n",
      "['likes', 2.09861228866811]\n",
      "['lottery', 2.09861228866811]\n",
      "['loves', 2.09861228866811]\n",
      "['matter', 2.09861228866811]\n",
      "['not', 2.09861228866811]\n",
      "['programmer', 2.09861228866811]\n",
      "['said', 2.09861228866811]\n",
      "['stay', 2.09861228866811]\n",
      "['the', 2.09861228866811]\n",
      "['to', 2.09861228866811]\n",
      "['want', 2.09861228866811]\n",
      "['we', 2.09861228866811]\n",
      "['what', 2.09861228866811]\n",
      "['wish', 2.09861228866811]\n",
      "['won', 2.09861228866811]\n",
      "['work', 2.09861228866811]\n"
     ]
    }
   ],
   "source": [
    "def df(t):\n",
    "    word_ind = vectorizor.vocabulary_[t]\n",
    "\n",
    "    tf_in_docus = da[:, word_ind]\n",
    "    existence_in_docus = tf_in_docus > 0\n",
    "\n",
    "    return existence_in_docus.sum()\n",
    "\n",
    "def idf(t, smooth_idf=True):\n",
    "    if smooth_idf:\n",
    "        return log((1 + n) / (1 + df(t))) + 1\n",
    "    else:\n",
    "        return log(n / df(t)) + 1\n",
    "    \n",
    "def tf_idf(t, d):\n",
    "    return idf(t) * tf(t, d)\n",
    "\n",
    "\n",
    "res_idf = []\n",
    "\n",
    "for word in vectorizor.get_feature_names_out():\n",
    "    tf_docus = []\n",
    "    res_idf.append([word, idf(word)])\n",
    "\n",
    "res_idf.sort(key=lambda x:x[1])\n",
    "\n",
    "for item in res_idf:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It does not matter what you are doing, just do it!',\n",
       " 'Would you work if you won the lottery?',\n",
       " 'You like Python, he likes Python, we like Python, everybody loves Python!',\n",
       " 'You said: \"I wish I were a Python programmer\"',\n",
       " 'You can stay here, if you want to. I would, if I were you.']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "it          : 0 4.20, 1 0.00, 2 0.00, 3 0.00, 4 0.00, \n",
      "does        : 0 2.10, 1 0.00, 2 0.00, 3 0.00, 4 0.00, \n",
      "not         : 0 2.10, 1 0.00, 2 0.00, 3 0.00, 4 0.00, \n",
      "matter      : 0 2.10, 1 0.00, 2 0.00, 3 0.00, 4 0.00, \n",
      "what        : 0 2.10, 1 0.00, 2 0.00, 3 0.00, 4 0.00, \n",
      "you         : 0 1.00, 1 2.00, 2 1.00, 3 1.00, 4 3.00, \n",
      "are         : 0 2.10, 1 0.00, 2 0.00, 3 0.00, 4 0.00, \n",
      "doing       : 0 2.10, 1 0.00, 2 0.00, 3 0.00, 4 0.00, \n",
      "just        : 0 2.10, 1 0.00, 2 0.00, 3 0.00, 4 0.00, \n",
      "do          : 0 2.10, 1 0.00, 2 0.00, 3 0.00, 4 0.00, \n",
      "would       : 0 0.00, 1 1.69, 2 0.00, 3 0.00, 4 1.69, \n",
      "work        : 0 0.00, 1 2.10, 2 0.00, 3 0.00, 4 0.00, \n",
      "if          : 0 0.00, 1 1.69, 2 0.00, 3 0.00, 4 3.39, \n",
      "won         : 0 0.00, 1 2.10, 2 0.00, 3 0.00, 4 0.00, \n",
      "the         : 0 0.00, 1 2.10, 2 0.00, 3 0.00, 4 0.00, \n",
      "lottery     : 0 0.00, 1 2.10, 2 0.00, 3 0.00, 4 0.00, \n",
      "like        : 0 0.00, 1 0.00, 2 4.20, 3 0.00, 4 0.00, \n",
      "python      : 0 0.00, 1 0.00, 2 6.77, 3 1.69, 4 0.00, \n",
      "he          : 0 0.00, 1 0.00, 2 2.10, 3 0.00, 4 0.00, \n",
      "likes       : 0 0.00, 1 0.00, 2 2.10, 3 0.00, 4 0.00, \n",
      "we          : 0 0.00, 1 0.00, 2 2.10, 3 0.00, 4 0.00, \n",
      "everybody   : 0 0.00, 1 0.00, 2 2.10, 3 0.00, 4 0.00, \n",
      "loves       : 0 0.00, 1 0.00, 2 2.10, 3 0.00, 4 0.00, \n",
      "said        : 0 0.00, 1 0.00, 2 0.00, 3 2.10, 4 0.00, \n",
      "wish        : 0 0.00, 1 0.00, 2 0.00, 3 2.10, 4 0.00, \n",
      "were        : 0 0.00, 1 0.00, 2 0.00, 3 1.69, 4 1.69, \n",
      "programmer  : 0 0.00, 1 0.00, 2 0.00, 3 2.10, 4 0.00, \n",
      "can         : 0 0.00, 1 0.00, 2 0.00, 3 0.00, 4 2.10, \n",
      "stay        : 0 0.00, 1 0.00, 2 0.00, 3 0.00, 4 2.10, \n",
      "here        : 0 0.00, 1 0.00, 2 0.00, 3 0.00, 4 2.10, \n",
      "want        : 0 0.00, 1 0.00, 2 0.00, 3 0.00, 4 2.10, \n",
      "to          : 0 0.00, 1 0.00, 2 0.00, 3 0.00, 4 2.10, "
     ]
    }
   ],
   "source": [
    "for word, word_index in vectorizor.vocabulary_.items():\n",
    "    print(f\"\\n{word:12s}: \", end='')\n",
    "\n",
    "    for d_index in range(len(corpus)):\n",
    "        print(f\"{d_index:1d} {tf_idf(word, d_index):3.2f}, \", end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cold', 'Cold wind', 'Cold wind blows', 'Cold wind blows over', 'Cold wind blows over the', 'Cold wind blows over the cornfields']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import text\n",
    "\n",
    "word = 'Cold wind blows over the cornfields'.split()\n",
    "\n",
    "corpus = []\n",
    "\n",
    "for i in range(1, len(word) + 1):\n",
    "    corpus.append(' '.join(word[:i]))\n",
    "\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizor = text.CountVectorizer()\n",
    "\n",
    "vectorizor = vectorizor.fit(corpus)\n",
    "vectorizor_text = vectorizor.transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.33647224, 1.        , 2.25276297, 1.55961579, 1.84729786,\n",
       "       1.15415068])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf = text.TfidfTransformer()\n",
    "tf_idf.fit(vectorizor_text)\n",
    "\n",
    "tf_idf.idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cold           : 1.000\n",
      "wind           : 1.154\n",
      "blows          : 1.336\n",
      "over           : 1.560\n",
      "the            : 1.847\n",
      "cornfields     : 2.253\n"
     ]
    }
   ],
   "source": [
    "word_weight_list = list(zip(vectorizor.get_feature_names_out(),\n",
    "                            tf_idf.idf_))\n",
    "word_weight_list.sort(key=lambda x:x[1])\n",
    "\n",
    "for word, idf_weight in word_weight_list:\n",
    "    print(f\"{word:15s}: {idf_weight:4.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cold           : 1.000\n",
      "wind           : 1.154\n",
      "blows          : 1.336\n",
      "over           : 1.560\n",
      "the            : 1.847\n",
      "cornfields     : 2.253\n"
     ]
    }
   ],
   "source": [
    "TfidF = text.TfidfTransformer(smooth_idf=True, use_idf=True)\n",
    "tfidf = TfidF.fit_transform(vectorizor_text)\n",
    "\n",
    "word_weight_list = list(zip(vectorizor.get_feature_names_out(),\n",
    "                            tf_idf.idf_))\n",
    "word_weight_list.sort(key=lambda x:x[1])\n",
    "\n",
    "for word, idf_weight in word_weight_list:\n",
    "    print(f\"{word:15s}: {idf_weight:4.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "vectorizor = CountVectorizer()\n",
    "\n",
    "newsgroups_data = fetch_20newsgroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(newsgroups_data.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Re: \"Proper gun control?\" What is proper gun cont\n",
      "From: kim39@scws8.harvard.edu (John Kim)\n",
      "Organization: Harvard University Science Center\n",
      "Nntp-Posting-Host: scws8.harvard.edu\n",
      "Lines: 17\n",
      "\n",
      "In article <C5JGz5.34J@SSD.intel.com> hays@ssd.intel.com (Kirk Hays) writes:\n",
      ">I'd like to point out that I was in error - \"Terminator\" began posting only \n",
      ">six months before he purchased his first firearm, according to private email\n",
      ">from him.\n",
      ">I can't produce an archived posting of his earlier than January 1992,\n",
      ">and he purchased his first firearm in March 1992.\n",
      ">I guess it only seemed like years.\n",
      ">Kirk Hays - NRA Life, seventh generation.\n",
      "\n",
      "I first read and consulted rec.guns in the summer of 1991.  I\n",
      "just purchased my first firearm in early March of this year.\n",
      "\n",
      " NOt for lack of desire for a firearm, you understand.  I could \n",
      "have purchased a rifle or shotgun but didn't want one.\n",
      "-Case Kim\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(newsgroups_data.data[200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizor.fit(newsgroups_data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from 56979\n",
      "lerxst 75358\n",
      "wam 123162\n",
      "umd 118280\n",
      "edu 50527\n",
      "where 124031\n",
      "my 85354\n",
      "thing 114688\n",
      "subject 111322\n",
      "what 123984\n",
      "car 37780\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "n = 10\n",
    "\n",
    "for word, index in vectorizor.vocabulary_.items():\n",
    "    print(word, index)\n",
    "    \n",
    "    counter += 1\n",
    "\n",
    "    if counter > n:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "a = vectorizor.transform([newsgroups_data.data[0]]).toarray()[0]\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130107"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizor.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups_data_cleaned = fetch_20newsgroups(remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n"
     ]
    }
   ],
   "source": [
    "print(newsgroups_data_cleaned.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101631"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizor_cleaned = vectorizor.fit(newsgroups_data_cleaned.data)\n",
    "len(vectorizor_cleaned.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "vectorizor = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.6460435475305364\n",
      "F1 score:  0.6203806145034193\n"
     ]
    }
   ],
   "source": [
    "train_data = vectorizor.fit_transform(newsgroups_train.data)\n",
    "\n",
    "classifier = MultinomialNB(alpha=0.01)\n",
    "classifier.fit(train_data, newsgroups_data.target)\n",
    "\n",
    "test_data = vectorizor.transform(newsgroups_test.data)\n",
    "\n",
    "predictions = classifier.predict(test_data)\n",
    "accuracy_score = metrics.accuracy_score(newsgroups_test.target, predictions)\n",
    "\n",
    "f1_Score = metrics.f1_score(newsgroups_test.target, predictions, average='macro')\n",
    "\n",
    "print('Accuracy score: ', accuracy_score)\n",
    "print('F1 score: ', f1_Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'horse': 5,\n",
       " 'kingdom': 8,\n",
       " 'sense': 16,\n",
       " 'thing': 18,\n",
       " 'keeps': 7,\n",
       " 'betting': 1,\n",
       " 'people': 13,\n",
       " 'often': 11,\n",
       " 'said': 15,\n",
       " 'nothing': 10,\n",
       " 'better': 0,\n",
       " 'inside': 6,\n",
       " 'man': 9,\n",
       " 'outside': 12,\n",
       " 'spiritually': 17,\n",
       " 'well': 20,\n",
       " 'physically': 14,\n",
       " 'bigger': 2,\n",
       " 'foot': 3,\n",
       " 'heaven': 4,\n",
       " 'welcome': 19}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [\"A horse, a horse, my kingdom for a horse!\",\n",
    "          \"Horse sense is the thing a horse has which keeps it from betting on people.\"\n",
    "          \"I’ve often said there is nothing better for the inside of the man, than the outside of the horse.\",\n",
    "          \"A man on a horse is spiritually, as well as physically, bigger then a man on foot.\",\n",
    "          \"No heaven can heaven be, if my horse isn’t there to welcome me.\"]\n",
    "\n",
    "cv = CountVectorizer(stop_words=[\"my\", \"for\",\"the\", \"has\", \"than\", \"if\", \n",
    "                                 \"from\", \"on\", \"of\", \"it\", \"there\", \"ve\",\n",
    "                                 \"as\", \"no\", \"be\", \"which\", \"isn\", \"to\", \n",
    "                                 \"me\", \"is\", \"can\", \"then\"])\n",
    "count_vector = cv.fit_transform(corpus)\n",
    "count_vector.shape\n",
    "\n",
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 arbitrary words from ENGLISH_STOP_WORDS:\n",
      "across, always, somehow, any, sincere, become, there, from, something, whose, myself, if, next, put, each, yet, though, anyone, bill, thick, cry, them, were, its, everything\n"
     ]
    }
   ],
   "source": [
    "n = 25\n",
    "\n",
    "print(str(n) + \" arbitrary words from ENGLISH_STOP_WORDS:\")\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for word in text.ENGLISH_STOP_WORDS:\n",
    "    if counter == n - 1:\n",
    "        print(word)\n",
    "        break\n",
    "\n",
    "    print(word, end=', ')\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.6526818906001062\n",
      "f1_Score:  0.6203806145034193\n"
     ]
    }
   ],
   "source": [
    "vectorizor = CountVectorizer(stop_words=list(text.ENGLISH_STOP_WORDS))\n",
    "\n",
    "vectors = vectorizor.fit_transform(newsgroups_train.data)\n",
    "\n",
    "classifier = MultinomialNB(alpha=0.01)\n",
    "classifier.fit(vectors, newsgroups_train.target)\n",
    "\n",
    "vectors_test = vectorizor.transform(newsgroups_test.data)\n",
    "\n",
    "predictions = classifier.predict(vectors_test)\n",
    "accuracy_score = metrics.accuracy_score(newsgroups_test.target, predictions)\n",
    "\n",
    "f1_score = metrics.f1_score(newsgroups_test.target, predictions, average='macro')\n",
    "\n",
    "print('accuracy score: ', accuracy_score)\n",
    "print('f1_Score: ', f1_Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'people': 7,\n",
       " 'you': 9,\n",
       " 'cannot': 0,\n",
       " 'is': 3,\n",
       " 'horse': 2,\n",
       " 'my': 5,\n",
       " 'for': 1,\n",
       " 'on': 6,\n",
       " 'there': 8,\n",
       " 'man': 4}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [\"\"\"People say you cannot live without love, \n",
    "             but I think oxygen is more important\"\"\",\n",
    "          \"Sometimes, when you close your eyes, you cannot see.\"\n",
    "          \"A horse, a horse, my kingdom for a horse!\",\n",
    "          \"\"\"Horse sense is the thing a horse has which \n",
    "          keeps it from betting on people.\"\"\"\n",
    "          \"\"\"I’ve often said there is nothing better for \n",
    "          the inside of the man, than the outside of the horse.\"\"\",\n",
    "          \"\"\"A man on a horse is spiritually, as well as physically, \n",
    "          bigger then a man on foot.\"\"\",\n",
    "          \"\"\"No heaven can heaven be, if my horse isn’t there \n",
    "          to welcome me.\"\"\"]\n",
    "\n",
    "cv = CountVectorizer(min_df=2)\n",
    "\n",
    "count_vector = cv.fit_transform(corpus)\n",
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'as',\n",
       " 'be',\n",
       " 'better',\n",
       " 'betting',\n",
       " 'bigger',\n",
       " 'but',\n",
       " 'can',\n",
       " 'close',\n",
       " 'eyes',\n",
       " 'foot',\n",
       " 'from',\n",
       " 'has',\n",
       " 'heaven',\n",
       " 'if',\n",
       " 'important',\n",
       " 'inside',\n",
       " 'isn',\n",
       " 'it',\n",
       " 'keeps',\n",
       " 'kingdom',\n",
       " 'live',\n",
       " 'love',\n",
       " 'me',\n",
       " 'more',\n",
       " 'no',\n",
       " 'nothing',\n",
       " 'of',\n",
       " 'often',\n",
       " 'outside',\n",
       " 'oxygen',\n",
       " 'physically',\n",
       " 'said',\n",
       " 'say',\n",
       " 'see',\n",
       " 'sense',\n",
       " 'sometimes',\n",
       " 'spiritually',\n",
       " 'than',\n",
       " 'the',\n",
       " 'then',\n",
       " 'thing',\n",
       " 'think',\n",
       " 'to',\n",
       " 've',\n",
       " 'welcome',\n",
       " 'well',\n",
       " 'when',\n",
       " 'which',\n",
       " 'without',\n",
       " 'your'}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.stop_words_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of docus, size of vocabulary, stop_words list size\n",
      "         0              60                   0\n",
      "         1              60                   0\n",
      "         2              10                  50\n",
      "         3               2                  58\n",
      "         4               1                  59\n"
     ]
    }
   ],
   "source": [
    "print('number of docus, size of vocabulary, stop_words list size')\n",
    "\n",
    "for i in range(len(corpus)):\n",
    "    cv = CountVectorizer(min_df=i)\n",
    "    count_vector = cv.fit_transform(corpus)\n",
    "\n",
    "    len_voc = len(cv.vocabulary_)\n",
    "    len_stop_words = len(cv.stop_words_)\n",
    "\n",
    "    print(f\"{i:10d} {len_voc:15d} {len_stop_words: 19d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cannot', 'for', 'horse', 'is', 'man', 'my', 'on', 'people', 'there', 'you'}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(max_df=0.20)\n",
    "\n",
    "count_vector = cv.fit_transform(corpus)\n",
    "cv.stop_words_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
